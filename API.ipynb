{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import psycopg2\n",
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=\"my_docs2\",\n",
    "    connection=\"postgresql+psycopg://stefan:gigelfrone112@localhost:5432/techvector\",\n",
    ")\n",
    "app = FastAPI()\n",
    "conn = psycopg2.connect(\"dbname=techvector user=stefan password=gigelfrone112 host=localhost port=5432\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_date_objects(data):\n",
    "    \"\"\"\n",
    "    Recursively traverses the JSON object and replaces every dictionary\n",
    "    containing 'date' and 'type' keys with the value of the 'date' key.\n",
    "\n",
    "    :param data: JSON object (dict, list, or other types)\n",
    "    :return: Updated JSON object\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        # Check if the current dictionary is the one to replace\n",
    "        if \"date\" in data and \"type\" in data:\n",
    "            return data[\"date\"]\n",
    "        # Otherwise, process each key-value pair\n",
    "        return {key: replace_date_objects(value) for key, value in data.items()}\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Process each element in the list\n",
    "        return [replace_date_objects(item) for item in data]\n",
    "\n",
    "    # Return the data as is for other types\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, Union\n",
    "\n",
    "from langchain_core.structured_query import (\n",
    "    Comparator,\n",
    "    Comparison,\n",
    "    Operation,\n",
    "    Operator,\n",
    "    StructuredQuery,\n",
    "    Visitor,\n",
    ")\n",
    "\n",
    "\n",
    "class CustomTranslator(Visitor):\n",
    "    \"\"\"Translate `PGVector` internal query language elements to valid filters.\"\"\"\n",
    "\n",
    "    allowed_operators = [Operator.AND, Operator.OR]\n",
    "    \"\"\"Subset of allowed logical operators.\"\"\"\n",
    "    allowed_comparators = [\n",
    "        Comparator.EQ,\n",
    "        Comparator.NE,\n",
    "        Comparator.GT,\n",
    "        Comparator.LT,\n",
    "        Comparator.IN,\n",
    "        Comparator.NIN,\n",
    "        Comparator.CONTAIN,\n",
    "        Comparator.LIKE,\n",
    "    ]\n",
    "    \"\"\"Subset of allowed logical comparators.\"\"\"\n",
    "\n",
    "    def _format_func(self, func: Union[Operator, Comparator]) -> str:\n",
    "        self._validate_func(func)\n",
    "        return f\"${func.value}\"\n",
    "\n",
    "    def visit_operation(self, operation: Operation) -> Dict:\n",
    "        args = [arg.accept(self) for arg in operation.arguments]\n",
    "        return {self._format_func(operation.operator): args}\n",
    "\n",
    "\n",
    "\n",
    "    def visit_comparison(self, comparison: Comparison) -> Dict:\n",
    "        return {\n",
    "            comparison.attribute: {\n",
    "                self._format_func(comparison.comparator): comparison.value\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "    def visit_structured_query(\n",
    "        self, structured_query: StructuredQuery\n",
    "    ) -> Tuple[str, dict]:\n",
    "        if structured_query.filter is None:\n",
    "            kwargs = {}\n",
    "        else:\n",
    "            kwargs = {\"filter\": structured_query.filter.accept(self)}\n",
    "            kwargs = replace_date_objects(kwargs)\n",
    "        return structured_query.query, kwargs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The title that the article was published under\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author\",\n",
    "        description=\"The name of the author of the article\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"date\",\n",
    "        description=\"The date that the article was published on, in the format 'YYYY-MM-DD'. If the month is given by its name, it is converted to its number.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"category\",\n",
    "        description=\"The category that the article belongs to. One of ['AI', 'Apps', 'Biotech & Health', 'Climate', 'Commerce', 'Crypto', 'Enterprise', 'Fintech', 'Fundraising', 'Gadgets', 'Gaming', 'Government & Policy', 'Hardware', 'Media & Entertainment', 'Privacy', 'Robotics', 'Security', 'Social', 'Space', 'Startups', 'Transportation', 'Venture']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"url\",\n",
    "        description=\"The URL to the original TechCrunch article\",\n",
    "        type=\"link\",\n",
    "    )\n",
    "]\n",
    "document_content_description = \"The article content\"\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vector_store,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    structured_query_translator=CustomTranslator(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=FewShotPromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, examples=[{'i': 1, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs by Taylor Swift or Katy Perry about teenage romance under 3 minutes long in the dance pop genre', 'structured_request': '```json\\n{{\\n    \"query\": \"teenager love\",\\n    \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"\\n}}\\n```'}, {'i': 2, 'data_source': '```json\\n{{\\n    \"content\": \"Lyrics of a song\",\\n    \"attributes\": {{\\n        \"artist\": {{\\n            \"type\": \"string\",\\n            \"description\": \"Name of the song artist\"\\n        }},\\n        \"length\": {{\\n            \"type\": \"integer\",\\n            \"description\": \"Length of the song in seconds\"\\n        }},\\n        \"genre\": {{\\n            \"type\": \"string\",\\n            \"description\": \"The song genre, one of \"pop\", \"rock\" or \"rap\"\"\\n        }}\\n    }}\\n}}\\n```', 'user_query': 'What are songs that were not published on Spotify', 'structured_request': '```json\\n{{\\n    \"query\": \"\",\\n    \"filter\": \"NO_FILTER\"\\n}}\\n```'}], example_prompt=PromptTemplate(input_variables=['data_source', 'i', 'structured_request', 'user_query'], input_types={}, partial_variables={}, template='<< Example {i}. >>\\nData Source:\\n{data_source}\\n\\nUser Query:\\n{user_query}\\n\\nStructured Request:\\n{structured_request}\\n'), suffix='<< Example 3. >>\\nData Source:\\n```json\\n{{\\n    \"content\": \"The article content\",\\n    \"attributes\": {{\\n    \"title\": {{\\n        \"description\": \"The title that the article was published under\",\\n        \"type\": \"string\"\\n    }},\\n    \"author\": {{\\n        \"description\": \"The name of the author of the article\",\\n        \"type\": \"string\"\\n    }},\\n    \"date\": {{\\n        \"description\": \"The date that the article was published on, in the format \\'YYYY-MM-DD\\'. If the month is given by its name, it is converted to its number.\",\\n        \"type\": \"string\"\\n    }},\\n    \"category\": {{\\n        \"description\": \"The category that the article belongs to. One of [\\'AI\\', \\'Apps\\', \\'Biotech & Health\\', \\'Climate\\', \\'Commerce\\', \\'Crypto\\', \\'Enterprise\\', \\'Fintech\\', \\'Fundraising\\', \\'Gadgets\\', \\'Gaming\\', \\'Government & Policy\\', \\'Hardware\\', \\'Media & Entertainment\\', \\'Privacy\\', \\'Robotics\\', \\'Security\\', \\'Social\\', \\'Space\\', \\'Startups\\', \\'Transportation\\', \\'Venture\\']\",\\n        \"type\": \"string\"\\n    }},\\n    \"url\": {{\\n        \"description\": \"The URL to the original TechCrunch article\",\\n        \"type\": \"link\"\\n    }}\\n}}\\n}}\\n```\\n\\nUser Query:\\n{query}\\n\\nStructured Request:\\n', prefix='Your goal is to structure the user\\'s query to match the request schema provided below.\\n\\n<< Structured Request Schema >>\\nWhen responding use a markdown code snippet with a JSON object formatted in the following schema:\\n\\n```json\\n{{\\n    \"query\": string \\\\ text string to compare to document contents\\n    \"filter\": string \\\\ logical condition statement for filtering documents\\n}}\\n```\\n\\nThe query string should contain only text that is expected to match the contents of documents. Any conditions in the filter should not be mentioned in the query as well.\\n\\nA logical condition statement is composed of one or more comparison and logical operation statements.\\n\\nA comparison statement takes the form: `comp(attr, val)`:\\n- `comp` (eq | ne | gt | lt | in | nin | contain | like): comparator\\n- `attr` (string):  name of attribute to apply the comparison to\\n- `val` (string): is the comparison value\\n\\nA logical operation statement takes the form `op(statement1, statement2, ...)`:\\n- `op` (and | or): logical operator\\n- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\\n\\nMake sure that you only use the comparators and logical operators listed above and no others.\\nMake sure that filters only refer to attributes that exist in the data source.\\nMake sure that filters only use the attributed names with its function names if there are functions applied on them.\\nMake sure that filters only use format `YYYY-MM-DD` when handling date data typed values.\\nMake sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored.\\nMake sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.')\n",
      "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x718a3c7482b0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x718a3c962680>, root_client=<openai.OpenAI object at 0x718a3898afe0>, root_async_client=<openai.AsyncOpenAI object at 0x718a3c748310>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
      "| StructuredQueryOutputParser(ast_parse=<bound method Lark.parse of Lark(open('<string>'), parser='lalr', lexer='contextual', ...)>) kwargs={} config={'run_name': 'query_constructor'} config_factories=[]\n",
      "structured query: query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.GT: 'gt'>, attribute='date', value={'date': '2025-01-01', 'type': 'date'}), Comparison(comparator=<Comparator.LT: 'lt'>, attribute='date', value={'date': '2025-01-06', 'type': 'date'})]) limit=None\n",
      "<__main__.CustomTranslator object at 0x718a3898a410>\n",
      "translated query: (' ', {'filter': {'$and': [{'date': {'$gt': '2025-01-01'}}, {'date': {'$lt': '2025-01-06'}}]}})\n",
      "result: [Document(id='e31b4b3d-5d80-4987-b97d-39f6fa037c40', metadata={'url': 'https://techcrunch.com/2025/01/03/chatgpt-everything-to-know-about-the-ai-chatbot/', 'date': '2025-01-03', 'title': 'ChatGPT: Everything you need to know about the AI-powered chatbot', 'author': 'Kyle Wiggers', 'category': 'AI', 'start_index': 39192}, page_content=\"This feature is being rolled out to a small portion of Free and Plus users, and it's easy to turn on or off. https://t.co/1Tv355oa7V pic.twitter.com/BsFinBSTbs\\n— OpenAI (@OpenAI) February 13, 2024\"), Document(id='20e53b79-1434-44aa-9b7c-ce5828d0812c', metadata={'url': 'https://techcrunch.com/2025/01/03/chatgpt-everything-to-know-about-the-ai-chatbot/', 'date': '2025-01-03', 'title': 'ChatGPT: Everything you need to know about the AI-powered chatbot', 'author': 'Kyle Wiggers', 'category': 'AI', 'start_index': 46772}, page_content='We build AI to empower people, including journalists.\\nOur position on the @nytimes lawsuit:• Training is fair use, but we provide an opt-out• \"Regurgitation\" is a rare bug we\\'re driving to zero• The New York Times is not telling the full storyhttps://t.co/S6fSaDsfKb\\n— OpenAI (@OpenAI) January 8, 2024'), Document(id='0800f6bc-3a87-4056-b553-d4ac6cbf9a39', metadata={'url': 'https://techcrunch.com/2025/01/02/meta-policy-chief-nick-clegg-steps-down/', 'date': '2025-01-02', 'title': 'Meta policy chief Nick Clegg steps down', 'author': 'Maxwell Zeff', 'category': 'Government & Policy', 'start_index': 1720}, page_content='By appointing a Republican to head Meta’s policy team, the company may be signaling it is willing to work more closely with conservatives in the incoming administration. Meta previously faced scrutiny from Republicans who alleged the company’s content moderation skewed to center-left politics and silenced right-wing voices. This included the company’s decision to ban Trump’s social media accounts following the January 6 insurrection.\\nIn the last year, Meta has made a concerted effort to appease Republicans. Meta removed all restrictions on Trump’s Facebook and Instagram accounts ahead of the 2024 election. In August, Zuckerberg sent a letter to House Republicans in which he apologized for bending to pressure from the Biden administration to “censor certain COVID-19 content.”\\nMeta did not immediately respond to TechCrunch’s request for comment.'), Document(id='02149620-3064-49d7-82bf-24d1a0dfe07c', metadata={'url': 'https://techcrunch.com/2025/01/05/youtuber-legaleagle-sues-paypal-over-sleeping-leech-honey-extension/', 'date': '2025-01-05', 'title': 'YouTuber LegalEagle sues PayPal over ‘sleeping leech’ Honey extension', 'author': 'Anthony Ha', 'category': 'Commerce', 'start_index': 1717}, page_content='Naturally, Stone also published a video about the lawsuit, which also emphasized Honey’s marketing efforts, in which creators promoted the browser extension to their audiences — and once those audiences installed it, Stone said it was like a “sleeping leech” in their browsers, “waiting for the viewer to conduct a transaction.”\\n“And thus, forever after, the creator’s future sponsorships and future affiliate relationships and advertisements were devalued now that the creator’s audience was infected,” he said.\\nStone added that he’s seeking class action status for the lawsuit and looking for other creators to join.')]\n"
     ]
    }
   ],
   "source": [
    "print(retriever.query_constructor)\n",
    "structured_query = retriever.query_constructor.invoke(input='Give me an article published between 1 and 5 January 2025')\n",
    "print(f\"structured query: {structured_query}\")\n",
    "# #print(retriever.structured_query_translator.visit_structured_query(structured_query))\n",
    "translated_query = retriever.structured_query_translator.visit_structured_query(structured_query)\n",
    "print(retriever.structured_query_translator)\n",
    "print(f\"translated query: {translated_query}\")\n",
    "result = vector_store.similarity_search(query=translated_query[0], filter=translated_query[1]['filter'])\n",
    "print(f\"result: {result}\")\n",
    "#print(retriever.query_constructor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/get_articles_by_query\")\n",
    "async def get_articles_by_query(query: str):\n",
    "    query = query.replace(\"'\", \"\\'\")\n",
    "    query = query.replace(\"’\", \"\\'\")\n",
    "    docs = retriever.invoke(query)\n",
    "    urls = list(set([doc.metadata[\"url\"] for doc in docs]))\n",
    "    print(urls)\n",
    "    cursor.execute(\"SELECT * FROM article WHERE link = ANY(%s);\", (urls,))\n",
    "    tuples = cursor.fetchall()\n",
    "    result_dict = [dict(zip(['url', 'title', 'time', 'img', 'category', 'summary', 'questions', 'author'], tup)) for tup in tuples]\n",
    "    return result_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/get_articles\")\n",
    "async def get_articles():\n",
    "    cursor.execute(\"SELECT * FROM article;\")\n",
    "    tuples = cursor.fetchall()\n",
    "    result_dict = [dict(zip(['url', 'title', 'time', 'img', 'category', 'summary', 'questions', 'author'], tup)) for tup in tuples]\n",
    "    return result_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/get_article\")\n",
    "async def get_article(url: str):\n",
    "    cursor.execute(f\"SELECT * FROM article where link = '{url}';\")\n",
    "    tuples = cursor.fetchone()\n",
    "    result_dict = dict(zip(['url', 'title', 'time', 'img', 'category', 'summary', 'questions', 'author'], tuples))\n",
    "    return result_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://techcrunch.com/2025/01/09/nvidias-ai-avatar-sat-on-my-computer-screen-and-weirded-me-out/']\n",
      "[{'url': 'https://techcrunch.com/2025/01/09/nvidias-ai-avatar-sat-on-my-computer-screen-and-weirded-me-out/', 'title': 'Nvidia’s AI avatar sat on my computer screen and weirded me out', 'time': '4:31 PM PST · January 9, 2025', 'img': 'https://techcrunch.com/wp-content/uploads/2025/01/IMG_9CC69B31B7BF-1.jpeg?w=1024', 'category': 'AI', 'summary': 'Nvidia has introduced R2X, a prototype AI avatar designed to assist users directly from their desktop, combining advanced AI models with a human-like interface. While it can navigate apps, process files, and even observe users’ screens, early demos reveal some quirks, like odd facial expressions and occasional inaccuracies in its guidance. The company plans to open source R2X in 2025, potentially allowing developers to create personalized AI interactions. Despite its promise, the technology still faces challenges, hinting at both the excitement and the uncertainties of integrating AI into everyday computing.', 'questions': 'What specific features does R2X offer for assisting users with applications?&&&How does Nvidia plan to address the issues observed in the early demos of R2X?&&&What are the implications of Nvidia’s plans to open source the R2X avatars for developers and users?', 'author': 'Maxwell Zeff'}]\n"
     ]
    }
   ],
   "source": [
    "print(await get_articles_by_query('Give me an article about AI published on 9 January, 2025 by Maxwell Zeff, talking about nvidia'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='28a48123-ef24-4cab-92c5-d008ca22b6a8', metadata={'url': 'https://techcrunch.com/2025/01/01/2024-the-year-silicon-valley-stifled-the-ai-doom-movement/', 'date': '2025-01-01', 'title': 'Silicon Valley stifled the AI doom movement in 2024', 'author': 'Maxwell Zeff', 'category': 'AI', 'start_index': 671}, page_content='In 2023, it seemed like we were in the beginning of a renaissance era for technology regulation. AI doom and AI safety — a broader subject that can encompass hallucinations, insufficient content moderation, and other ways AI can harm society — went from a niche topic discussed in San Francisco coffee shops to a conversation appearing on MSNBC, CNN, and the front pages of The New York Times.'), Document(id='0f627b31-c55d-4440-8b49-7ced0c7b820f', metadata={'url': 'https://techcrunch.com/2025/01/01/openai-failed-to-deliver-the-opt-out-tool-it-promised-by-2025/', 'date': '2025-01-01', 'title': 'OpenAI failed to deliver the opt-out tool it promised by 2025', 'author': 'Kyle Wiggers', 'category': 'AI', 'start_index': 6526}, page_content='Media Manager might not even be especially advantageous for OpenAI, at least from a jurisprudential standpoint. Evan Everist, a partner at Dorsey & Whitney specializing in copyright law, said that while OpenAI could use the tool to show a judge it’s mitigating its training on IP-protected content, Media Manager likely wouldn’t shield the company from damages if it was found to have infringed.\\n“Copyright owners do not have an obligation to go out and preemptively tell others not to infringe their works before that infringement occurs,” Everist said. “The basics of copyright law still apply — i.e., don’t take and copy other people’s stuff without permission. This feature may be more about PR and positioning OpenAI as an ethical user of content.”\\nA reckoning'), Document(id='ff3cfd6c-b4ae-428e-a1fd-49b044459373', metadata={'url': 'https://techcrunch.com/2025/01/01/2024-the-year-silicon-valley-stifled-the-ai-doom-movement/', 'date': '2025-01-01', 'title': 'Silicon Valley stifled the AI doom movement in 2024', 'author': 'Maxwell Zeff', 'category': 'AI', 'start_index': 11322}, page_content='TechCrunch has an AI-focused newsletter!\\xa0Sign up here\\xa0to get it in your inbox every Wednesday.'), Document(id='ce1d3c64-9586-4af0-b1b6-ad8d1e6417cc', metadata={'url': 'https://techcrunch.com/2025/01/01/openai-failed-to-deliver-the-opt-out-tool-it-promised-by-2025/', 'date': '2025-01-01', 'title': 'OpenAI failed to deliver the opt-out tool it promised by 2025', 'author': 'Kyle Wiggers', 'category': 'AI', 'start_index': 5001}, page_content='“Ensuring compliance with legally required creator protections and potential compensation requirements under consideration presents challenges,” Cyhan told TechCrunch, “especially given the rapidly-evolving and potentially divergent legal landscape across national and local jurisdictions.”\\nEd Newton-Rex, the founder of Fairly Trained, a nonprofit that certifies AI companies are respecting creators’ rights, believes that Media Manager would unfairly shift the burden of controlling AI training onto creators; by not using it, they arguably could be giving tacit approval for their works to be used. “Most creators will never even hear about it, let alone use it,” he told TechCrunch. “But it will nevertheless be used to defend the mass exploitation of creative work against creators’ wishes.”')]\n"
     ]
    }
   ],
   "source": [
    "result = vector_store.similarity_search(query = \" \", filter = {'$and': [{'category': {'$eq': 'AI'}}, {'date': {'$eq': '2025-01-01'}}]})\n",
    "print(result)\n",
    "#result = vector_store.similarity_search(query = \"AI\", filter = {\"time\": {\"$eq\": \"2025-01-10\"}})\n",
    "#print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT RELATED TO APIS: modifying metadata: from time, to just date and removed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_postgres.vectorstores._get_embedding_collection_store.<locals>.EmbeddingStore object at 0x718a3c111f00>\n",
      "1261\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "from sqlalchemy.orm import Session\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "vectorstore = PGVector(\n",
    "    embeddings=embeddings, collection_name=\"my_docs2\",\n",
    "    connection=\"postgresql+psycopg://stefan:gigelfrone112@localhost:5432/techvector\", use_jsonb=True)\n",
    "\n",
    "with Session(vectorstore.session_maker.bind) as session:\n",
    "    docs = session.query(vectorstore.EmbeddingStore).all()\n",
    "\n",
    "print(docs[0])\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://techcrunch.com/2025/01/01/2024-the-year-silicon-valley-stifled-the-ai-doom-movement/', 'date': '2025-01-01', 'title': 'Silicon Valley stifled the AI doom movement in 2024', 'author': 'Maxwell Zeff', 'category': 'AI', 'start_index': 11322}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].cmetadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modifying metadata for time to just date\n",
    "\n",
    "from multiprocessing import connection\n",
    "\n",
    "date_conversion = {'January': '1', 'February': '2', 'March': '3', 'April': '4', 'May': '5', 'June': '6', 'July': '7', 'August': '8', 'September': '9', 'October': '10', 'November': '11', 'December': '12'}\n",
    "\n",
    "\n",
    "original_metadata = [doc.cmetadata for doc in docs]\n",
    "for doc in original_metadata:\n",
    "    # time = doc['time']\n",
    "    # time = time.replace(',', '')\n",
    "    # time = time.split(' ')\n",
    "    # time = f\"{time[2]}-{date_conversion[time[0]].zfill(2)}-{time[1].zfill(2)}\"\n",
    "    # doc['time'] = time\n",
    "    doc['date'] = doc['time']['date'] #{'date': doc['time']['date'], 'type': 'date'}\n",
    "    doc.pop('time')\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "texts = [doc.document for doc in docs]\n",
    "embeddings = [doc.embedding for doc in docs]\n",
    "text_embedding = list(zip(texts, embeddings))\n",
    "vector_store = PGVector.from_embeddings(text_embeddings=text_embedding, \n",
    "                                        embedding=embeddings,\n",
    "                                        metadatas=original_metadata,\n",
    "                                        connection=\"postgresql+psycopg://stefan:gigelfrone112@localhost:5432/techvector\",\n",
    "                                        collection_name=\"my_docs2\",\n",
    "                                        pre_delete_collection=True)\n",
    "\n",
    "#todo iterate through all docs WITH METADATA, modify metadata for time to just date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1261\n"
     ]
    }
   ],
   "source": [
    "ids_to_delete = [doc.id for doc in docs if \"image\" in doc.cmetadata]\n",
    "print(len(ids_to_delete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.delete(ids_to_delete)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
