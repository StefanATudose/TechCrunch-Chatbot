{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import psycopg2\n",
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=\"my_docs2\",\n",
    "    connection=\"postgresql+psycopg://stefan:gigelfrone112@localhost:5432/techvector\",\n",
    ")\n",
    "app = FastAPI()\n",
    "conn = psycopg2.connect(\"dbname=techvector user=stefan password=gigelfrone112 host=localhost port=5432\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_date_objects(data):\n",
    "    \"\"\"\n",
    "    Recursively traverses the JSON object and replaces every dictionary\n",
    "    containing 'date' and 'type' keys with the value of the 'date' key.\n",
    "\n",
    "    :param data: JSON object (dict, list, or other types)\n",
    "    :return: Updated JSON object\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        # Check if the current dictionary is the one to replace\n",
    "        if \"date\" in data and \"type\" in data:\n",
    "            return data[\"date\"]\n",
    "        # Otherwise, process each key-value pair\n",
    "        return {key: replace_date_objects(value) for key, value in data.items()}\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Process each element in the list\n",
    "        return [replace_date_objects(item) for item in data]\n",
    "\n",
    "    # Return the data as is for other types\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, Union\n",
    "\n",
    "from langchain_core.structured_query import (\n",
    "    Comparator,\n",
    "    Comparison,\n",
    "    Operation,\n",
    "    Operator,\n",
    "    StructuredQuery,\n",
    "    Visitor,\n",
    ")\n",
    "\n",
    "\n",
    "class CustomTranslator(Visitor):\n",
    "    \"\"\"Translate `PGVector` internal query language elements to valid filters.\"\"\"\n",
    "\n",
    "    allowed_operators = [Operator.AND, Operator.OR]\n",
    "    \"\"\"Subset of allowed logical operators.\"\"\"\n",
    "    allowed_comparators = [\n",
    "        Comparator.EQ,\n",
    "        Comparator.NE,\n",
    "        Comparator.GT,\n",
    "        Comparator.LT,\n",
    "        Comparator.IN,\n",
    "        Comparator.NIN,\n",
    "        Comparator.CONTAIN,\n",
    "        Comparator.LIKE,\n",
    "    ]\n",
    "    \"\"\"Subset of allowed logical comparators.\"\"\"\n",
    "\n",
    "    def _format_func(self, func: Union[Operator, Comparator]) -> str:\n",
    "        self._validate_func(func)\n",
    "        return f\"${func.value}\"\n",
    "\n",
    "    def visit_operation(self, operation: Operation) -> Dict:\n",
    "        args = [arg.accept(self) for arg in operation.arguments]\n",
    "        return {self._format_func(operation.operator): args}\n",
    "\n",
    "\n",
    "\n",
    "    def visit_comparison(self, comparison: Comparison) -> Dict:\n",
    "        return {\n",
    "            comparison.attribute: {\n",
    "                self._format_func(comparison.comparator): comparison.value\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "    def visit_structured_query(\n",
    "        self, structured_query: StructuredQuery\n",
    "    ) -> Tuple[str, dict]:\n",
    "        if structured_query.filter is None:\n",
    "            kwargs = {}\n",
    "        else:\n",
    "            kwargs = {\"filter\": structured_query.filter.accept(self)}\n",
    "            kwargs = replace_date_objects(kwargs)\n",
    "        return structured_query.query, kwargs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The title that the article was published under\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author\",\n",
    "        description=\"The name of the author of the article\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"date\",\n",
    "        description=\"The date that the article was published on, in the format 'YYYY-MM-DD'. If the month is given by its name, it is converted to its number.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"category\",\n",
    "        description=\"The category that the article belongs to. One of ['AI', 'Apps', 'Biotech & Health', 'Climate', 'Commerce', 'Crypto', 'Enterprise', 'Fintech', 'Fundraising', 'Gadgets', 'Gaming', 'Government & Policy', 'Hardware', 'Media & Entertainment', 'Privacy', 'Robotics', 'Security', 'Social', 'Space', 'Startups', 'Transportation', 'Venture']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"url\",\n",
    "        description=\"The URL to the original TechCrunch article\",\n",
    "        type=\"link\",\n",
    "    )\n",
    "]\n",
    "document_content_description = \"The article content\"\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vector_store,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    structured_query_translator=CustomTranslator(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/get_articles_by_query\")\n",
    "async def get_articles_by_query(query: str):\n",
    "    query = query.replace(\"'\", \"\\'\")\n",
    "    query = query.replace(\"’\", \"\\'\")\n",
    "    docs = retriever.invoke(query)\n",
    "    urls = list(set([doc.metadata[\"url\"] for doc in docs]))\n",
    "    cursor.execute(\"SELECT * FROM article WHERE link = ANY(%s);\", (urls,))\n",
    "    tuples = cursor.fetchall()\n",
    "    result_dict = [dict(zip(['url', 'title', 'time', 'img', 'category', 'summary', 'questions', 'author'], tup)) for tup in tuples]\n",
    "    return result_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/get_articles\")\n",
    "async def get_articles():\n",
    "    cursor.execute(\"SELECT * FROM article;\")\n",
    "    tuples = cursor.fetchall()\n",
    "    result_dict = [dict(zip(['url', 'title', 'time', 'img', 'category', 'summary', 'questions', 'author'], tup)) for tup in tuples]\n",
    "    return result_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/get_article\")\n",
    "async def get_article(url: str):\n",
    "    cursor.execute(f\"SELECT * FROM article where link = '{url}';\")\n",
    "    tuples = cursor.fetchone()\n",
    "    result_dict = dict(zip(['url', 'title', 'time', 'img', 'category', 'summary', 'questions', 'author'], tuples))\n",
    "    return result_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://techcrunch.com/2025/01/09/nvidias-ai-avatar-sat-on-my-computer-screen-and-weirded-me-out/', 'title': 'Nvidia’s AI avatar sat on my computer screen and weirded me out', 'time': '4:31 PM PST · January 9, 2025', 'img': 'https://techcrunch.com/wp-content/uploads/2025/01/IMG_9CC69B31B7BF-1.jpeg?w=1024', 'category': 'AI', 'summary': 'Nvidia has introduced R2X, a prototype AI avatar designed to assist users directly from their desktop, combining advanced AI models with a human-like interface. While it can navigate apps, process files, and even observe users’ screens, early demos reveal some quirks, like odd facial expressions and occasional inaccuracies in its guidance. The company plans to open source R2X in 2025, potentially allowing developers to create personalized AI interactions. Despite its promise, the technology still faces challenges, hinting at both the excitement and the uncertainties of integrating AI into everyday computing.', 'questions': 'What specific features does R2X offer for assisting users with applications?&&&How does Nvidia plan to address the issues observed in the early demos of R2X?&&&What are the implications of Nvidia’s plans to open source the R2X avatars for developers and users?', 'author': 'Maxwell Zeff'}]\n"
     ]
    }
   ],
   "source": [
    "print(await get_articles_by_query('Give me an article about AI published on 9 January, 2025 by Maxwell Zeff, talking about nvidia'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import InjectedToolArg, tool\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.graph import MessagesState, StateGraph\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from copy import deepcopy\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):#, url: Annotated[str, InjectedToolArg]) -> Tuple[str, list]:\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=3)#, filter={\"url\": {'$eq': url}})\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@chain\n",
    "def inject_user_id(ai_msg):\n",
    "    tool_calls = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        tool_call_copy = deepcopy(tool_call)\n",
    "        tool_call_copy[\"args\"][\"user_id\"] = user_id\n",
    "        tool_calls.append(tool_call_copy)\n",
    "    return tool_calls\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me the latest news about Elon Musk.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_Euv3LPbe7j7NSjyLUNPJOggN)\n",
      " Call ID: call_Euv3LPbe7j7NSjyLUNPJOggN\n",
      "  Args:\n",
      "    query: latest news about Elon Musk\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'url': 'https://techcrunch.com/2025/01/02/police-investigating-cybertruck-fire-outside-trump-hotel-in-vegas/', 'date': '2025-01-02', 'title': 'New details emerge in Cybertruck explosion outside Trump hotel in Vegas that left 1 dead, 7 injured', 'author': 'Kirsten Korosec', 'category': 'Transportation', 'start_index': 4378}\n",
      "Content: McMahill personally thanked Musk for providing law enforcement with specific information about the operation of the Cybertruck as well as video from Tesla charging stations used by the individual.\n",
      "The incident comes as Musk, who also owns X, maintains a close connection to President-elect Donald Trump. A review of Musk’s flight data showed at least 31 flights to or from Trump’s Mar-a-Lago property in Florida. This week, the NYT reported that Musk has been staying at a cottage on the Mar-a-Lago property.\n",
      "This article has been updated with new information, including that the explosion left one person dead and several injured, what contents were found in the vehicle, and images.\n",
      "\n",
      "Source: {'url': 'https://techcrunch.com/2025/01/05/bad-news-for-adrian-dittman-elon-musk-truthers/', 'date': '2025-01-05', 'title': 'Bad news for Adrian Dittmann/Elon Musk truthers', 'author': 'Anthony Ha', 'category': 'In Brief', 'start_index': 0}\n",
      "Content: Bad news for Adrian Dittmann/Elon Musk truthers\n",
      "After days of speculation that X owner Elon Musk was secretly posting under an account named Adrian Dittmann, new evidence suggests Dittmann is, in fact, a real person living in Fiji.\n",
      "Attempts to connect Dittmann and Musk go back at least to 2023; Dittmann frequently makes fawning posts about Musk, and his voice (as heard on numerous X Spaces) sounds quite similar.\n",
      "But a story in The Spectator appears to have identified the real Dittmann, the son of a German software entrepreneur who’s started multiple companies in Fiji. This Dittmann was included in a Fijian government video of a recent warehouse opening.\n",
      "\n",
      "Source: {'url': 'https://techcrunch.com/2025/01/02/police-investigating-cybertruck-fire-outside-trump-hotel-in-vegas/', 'date': '2025-01-02', 'title': 'New details emerge in Cybertruck explosion outside Trump hotel in Vegas that left 1 dead, 7 injured', 'author': 'Kirsten Korosec', 'category': 'Transportation', 'start_index': 3769}\n",
      "Content: Tesla CEO Elon Musk posted several notes on X, initially stating that the “whole senior Tesla team is investigating” the incident. “Will post more information as soon as we learn anything. We’ve never seen anything like this,” Musk wrote.\n",
      "Musk later posted that the vehicle was operating as normal, according to telemetry data he said the Tesla team viewed.\n",
      "“We have now confirmed that the explosion was caused by very large fireworks and/or a bomb carried in the bed of the rented Cybertruck and is unrelated to the vehicle itself. All vehicle telemetry was positive at the time of the explosion,” he wrote.\n",
      "McMahill personally thanked Musk for providing law enforcement with specific information about the operation of the Cybertruck as well as video from Tesla charging stations used by the individual.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The latest news about Elon Musk includes his involvement in the investigation of a Cybertruck explosion outside the Trump hotel in Las Vegas, which left one person dead and several injured. Musk stated that the explosion was caused by large fireworks or a bomb in the vehicle, and confirmed that the vehicle was operating normally at the time. Additionally, he has been linked to President-elect Donald Trump through multiple flights to Mar-a-Lago.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Tell me the latest news about Elon Musk.\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plan for next api:\n",
    "#chatbot on document splits of same article(fetched by article url)\n",
    "#q&a bot with memory\n",
    "\n",
    "@app.get(\"/continue_conversation\")\n",
    "async def continue_conversation(url: str, query: str):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT RELATED TO APIS: modifying metadata: from time, to just date and removed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_postgres.vectorstores._get_embedding_collection_store.<locals>.EmbeddingStore object at 0x718a3c111f00>\n",
      "1261\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "from sqlalchemy.orm import Session\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "vectorstore = PGVector(\n",
    "    embeddings=embeddings, collection_name=\"my_docs2\",\n",
    "    connection=\"postgresql+psycopg://stefan:gigelfrone112@localhost:5432/techvector\", use_jsonb=True)\n",
    "\n",
    "with Session(vectorstore.session_maker.bind) as session:\n",
    "    docs = session.query(vectorstore.EmbeddingStore).all()\n",
    "\n",
    "print(docs[0])\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://techcrunch.com/2025/01/01/2024-the-year-silicon-valley-stifled-the-ai-doom-movement/', 'date': '2025-01-01', 'title': 'Silicon Valley stifled the AI doom movement in 2024', 'author': 'Maxwell Zeff', 'category': 'AI', 'start_index': 11322}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].cmetadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modifying metadata for time to just date\n",
    "\n",
    "from multiprocessing import connection\n",
    "\n",
    "date_conversion = {'January': '1', 'February': '2', 'March': '3', 'April': '4', 'May': '5', 'June': '6', 'July': '7', 'August': '8', 'September': '9', 'October': '10', 'November': '11', 'December': '12'}\n",
    "\n",
    "\n",
    "original_metadata = [doc.cmetadata for doc in docs]\n",
    "for doc in original_metadata:\n",
    "    # time = doc['time']\n",
    "    # time = time.replace(',', '')\n",
    "    # time = time.split(' ')\n",
    "    # time = f\"{time[2]}-{date_conversion[time[0]].zfill(2)}-{time[1].zfill(2)}\"\n",
    "    # doc['time'] = time\n",
    "    doc['date'] = doc['time']['date'] #{'date': doc['time']['date'], 'type': 'date'}\n",
    "    doc.pop('time')\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "texts = [doc.document for doc in docs]\n",
    "embeddings = [doc.embedding for doc in docs]\n",
    "text_embedding = list(zip(texts, embeddings))\n",
    "vector_store = PGVector.from_embeddings(text_embeddings=text_embedding, \n",
    "                                        embedding=embeddings,\n",
    "                                        metadatas=original_metadata,\n",
    "                                        connection=\"postgresql+psycopg://stefan:gigelfrone112@localhost:5432/techvector\",\n",
    "                                        collection_name=\"my_docs2\",\n",
    "                                        pre_delete_collection=True)\n",
    "\n",
    "#todo iterate through all docs WITH METADATA, modify metadata for time to just date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1261\n"
     ]
    }
   ],
   "source": [
    "ids_to_delete = [doc.id for doc in docs if \"image\" in doc.cmetadata]\n",
    "print(len(ids_to_delete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.delete(ids_to_delete)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
