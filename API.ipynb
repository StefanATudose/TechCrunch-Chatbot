{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import psycopg2\n",
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=\"my_docs2\",\n",
    "    connection=\"postgresql+psycopg://stefan:gigelfrone112@localhost:5432/techvector\",\n",
    ")\n",
    "app = FastAPI()\n",
    "conn = psycopg2.connect(\"dbname=techvector user=stefan password=gigelfrone112 host=localhost port=5432\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_date_objects(data):\n",
    "    \"\"\"\n",
    "    Recursively traverses the JSON object and replaces every dictionary\n",
    "    containing 'date' and 'type' keys with the value of the 'date' key.\n",
    "\n",
    "    :param data: JSON object (dict, list, or other types)\n",
    "    :return: Updated JSON object\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        # Check if the current dictionary is the one to replace\n",
    "        if \"date\" in data and \"type\" in data:\n",
    "            return data[\"date\"]\n",
    "        # Otherwise, process each key-value pair\n",
    "        return {key: replace_date_objects(value) for key, value in data.items()}\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        # Process each element in the list\n",
    "        return [replace_date_objects(item) for item in data]\n",
    "\n",
    "    # Return the data as is for other types\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, Union\n",
    "\n",
    "from langchain_core.structured_query import (\n",
    "    Comparator,\n",
    "    Comparison,\n",
    "    Operation,\n",
    "    Operator,\n",
    "    StructuredQuery,\n",
    "    Visitor,\n",
    ")\n",
    "\n",
    "\n",
    "class CustomTranslator(Visitor):\n",
    "    \"\"\"Translate `PGVector` internal query language elements to valid filters.\"\"\"\n",
    "\n",
    "    allowed_operators = [Operator.AND, Operator.OR]\n",
    "    \"\"\"Subset of allowed logical operators.\"\"\"\n",
    "    allowed_comparators = [\n",
    "        Comparator.EQ,\n",
    "        Comparator.NE,\n",
    "        Comparator.GT,\n",
    "        Comparator.LT,\n",
    "        Comparator.IN,\n",
    "        Comparator.NIN,\n",
    "        Comparator.CONTAIN,\n",
    "        Comparator.LIKE,\n",
    "    ]\n",
    "    \"\"\"Subset of allowed logical comparators.\"\"\"\n",
    "\n",
    "    def _format_func(self, func: Union[Operator, Comparator]) -> str:\n",
    "        self._validate_func(func)\n",
    "        return f\"${func.value}\"\n",
    "\n",
    "    def visit_operation(self, operation: Operation) -> Dict:\n",
    "        args = [arg.accept(self) for arg in operation.arguments]\n",
    "        return {self._format_func(operation.operator): args}\n",
    "\n",
    "\n",
    "\n",
    "    def visit_comparison(self, comparison: Comparison) -> Dict:\n",
    "        return {\n",
    "            comparison.attribute: {\n",
    "                self._format_func(comparison.comparator): comparison.value\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "    def visit_structured_query(\n",
    "        self, structured_query: StructuredQuery\n",
    "    ) -> Tuple[str, dict]:\n",
    "        if structured_query.filter is None:\n",
    "            kwargs = {}\n",
    "        else:\n",
    "            kwargs = {\"filter\": structured_query.filter.accept(self)}\n",
    "            kwargs = replace_date_objects(kwargs)\n",
    "        return structured_query.query, kwargs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The title that the article was published under\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"author\",\n",
    "        description=\"The name of the author of the article\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"date\",\n",
    "        description=\"The date that the article was published on, in the format 'YYYY-MM-DD'. If the month is given by its name, it is converted to its number.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"category\",\n",
    "        description=\"The category that the article belongs to. One of ['AI', 'Apps', 'Biotech & Health', 'Climate', 'Commerce', 'Crypto', 'Enterprise', 'Fintech', 'Fundraising', 'Gadgets', 'Gaming', 'Government & Policy', 'Hardware', 'Media & Entertainment', 'Privacy', 'Robotics', 'Security', 'Social', 'Space', 'Startups', 'Transportation', 'Venture']\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"url\",\n",
    "        description=\"The URL to the original TechCrunch article\",\n",
    "        type=\"link\",\n",
    "    )\n",
    "]\n",
    "document_content_description = \"The article content\"\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vector_store,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    structured_query_translator=CustomTranslator(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/get_articles_by_query\")\n",
    "async def get_articles_by_query(query: str):\n",
    "    query = query.replace(\"'\", \"\\'\")\n",
    "    query = query.replace(\"’\", \"\\'\")\n",
    "    docs = retriever.invoke(query)\n",
    "    urls = list(set([doc.metadata[\"url\"] for doc in docs]))\n",
    "    cursor.execute(\"SELECT * FROM article WHERE link = ANY(%s);\", (urls,))\n",
    "    tuples = cursor.fetchall()\n",
    "    result_dict = [dict(zip(['url', 'title', 'time', 'img', 'category', 'summary', 'questions', 'author'], tup)) for tup in tuples]\n",
    "    return result_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/get_articles\")\n",
    "async def get_articles():\n",
    "    cursor.execute(\"SELECT * FROM article;\")\n",
    "    tuples = cursor.fetchall()\n",
    "    result_dict = [dict(zip(['url', 'title', 'time', 'img', 'category', 'summary', 'questions', 'author'], tup)) for tup in tuples]\n",
    "    return result_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/get_article\")\n",
    "async def get_article(url: str):\n",
    "    cursor.execute(f\"SELECT * FROM article where link = '{url}';\")\n",
    "    tuples = cursor.fetchone()\n",
    "    result_dict = dict(zip(['url', 'title', 'time', 'img', 'category', 'summary', 'questions', 'author'], tuples))\n",
    "    return result_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://techcrunch.com/2025/01/09/nvidias-ai-avatar-sat-on-my-computer-screen-and-weirded-me-out/', 'title': 'Nvidia’s AI avatar sat on my computer screen and weirded me out', 'time': '4:31 PM PST · January 9, 2025', 'img': 'https://techcrunch.com/wp-content/uploads/2025/01/IMG_9CC69B31B7BF-1.jpeg?w=1024', 'category': 'AI', 'summary': 'Nvidia has introduced R2X, a prototype AI avatar designed to assist users directly from their desktop, combining advanced AI models with a human-like interface. While it can navigate apps, process files, and even observe users’ screens, early demos reveal some quirks, like odd facial expressions and occasional inaccuracies in its guidance. The company plans to open source R2X in 2025, potentially allowing developers to create personalized AI interactions. Despite its promise, the technology still faces challenges, hinting at both the excitement and the uncertainties of integrating AI into everyday computing.', 'questions': 'What specific features does R2X offer for assisting users with applications?&&&How does Nvidia plan to address the issues observed in the early demos of R2X?&&&What are the implications of Nvidia’s plans to open source the R2X avatars for developers and users?', 'author': 'Maxwell Zeff'}]\n"
     ]
    }
   ],
   "source": [
    "print(await get_articles_by_query('Give me an article about AI published on 9 January, 2025 by Maxwell Zeff, talking about nvidia'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import InjectedToolArg, tool\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.graph import MessagesState, StateGraph\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from copy import deepcopy\n",
    "from langchain_core.runnables import chain\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):#, url: Annotated[str, InjectedToolArg]) -> Tuple[str, list]:\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=3)#, filter={\"url\": {'$eq': url}})\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from psycopg import Connection\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "db_url = \"postgresql://stefan:gigelfrone112@localhost:5432/techvector\"\n",
    "\n",
    "postgresCheckpointer = PostgresSaver(Connection.connect(db_url))\n",
    "\n",
    "#postgresCheckpointer.setup()\n",
    "graph = graph_builder.compile(checkpointer=postgresCheckpointer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Do you still remember what I asked first?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yes, you initially asked for the latest news about Elon Musk.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Do you still remember what I asked first?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plan for next api:\n",
    "#chatbot on document splits of same article(fetched by article url)\n",
    "#q&a bot with memory\n",
    "\n",
    "@app.get(\"/continue_conversation\")\n",
    "async def continue_conversation(url: str, query: str):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "\n",
    "class CustomState(MessagesState):\n",
    "    url: str\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_by_url(query: str, url: Annotated[str, InjectedToolArg]) -> Tuple[str, list]:\n",
    "    \"\"\"Retrieve information related to a query, only fetching documents with a specific URL.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=10, filter={\"url\": {'$eq': url}})\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond_custom(state: CustomState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve_by_url])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    for call in response.tool_calls:\n",
    "        call[\"args\"][\"url\"] = state['url']\n",
    "\n",
    "\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools_by_url = ToolNode([retrieve_by_url])\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate_custom(state: CustomState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(CustomState)\n",
    "\n",
    "workflow.add_node(tools_by_url)\n",
    "workflow.add_node(query_or_respond_custom)\n",
    "workflow.add_node(generate_custom)\n",
    "\n",
    "workflow.set_entry_point(\"query_or_respond_custom\")\n",
    "workflow.add_edge(\"tools\", \"generate_custom\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"query_or_respond_custom\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"generate_custom\", END)\n",
    "\n",
    "db_url = \"postgresql://stefan:gigelfrone112@localhost:5432/techvector\"\n",
    "\n",
    "postgresCheckpointer = PostgresSaver(Connection.connect(db_url))\n",
    "\n",
    "#postgresCheckpointer.setup()\n",
    "url_graph = workflow.compile(checkpointer=postgresCheckpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I know for sure it it in U.S.'s top 10 healthcare systems in terms of customers. Please try again\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_by_url (call_3jIXYHTY4aIBmLznZ1OQaJGw)\n",
      " Call ID: call_3jIXYHTY4aIBmLznZ1OQaJGw\n",
      "  Args:\n",
      "    query: Innovacer ranking healthcare companies\n",
      "    url: https://techcrunch.com/2025/01/09/innovaccer-aims-to-become-healthcares-ai-powerhouse-with-275m-series-f/\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_by_url\n",
      "\n",
      "Source: {'url': 'https://techcrunch.com/2025/01/09/innovaccer-aims-to-become-healthcares-ai-powerhouse-with-275m-series-f/', 'date': '2025-01-09', 'title': 'Innovaccer aims to become healthcare’s AI powerhouse with $275M Series F', 'author': 'Marina Temkin', 'category': 'Biotech & Health', 'start_index': 3410}\n",
      "Content: Although it’s unclear how many healthcare providers can compete with Innovaccer in the breadth of services it offers, the company does have competition in specific niches. For example, in population health management, it competes with major players like Optum and Health Catalyst. In the CRM space, Salesforce is a significant rival.\n",
      "Shashank said that while Innovaccer has its sights on an IPO, the company won’t seriously consider that route until it is generating $400 million to $500 million in ARR.\n",
      "The company is now squarely focused on creating a platform for AI applications on top of its infrastructure layer. Shashank hopes that instead of buying AI tools from many different companies, customers will choose Innovaccer for all their AI needs.\n",
      "\n",
      "Source: {'url': 'https://techcrunch.com/2025/01/09/innovaccer-aims-to-become-healthcares-ai-powerhouse-with-275m-series-f/', 'date': '2025-01-09', 'title': 'Innovaccer aims to become healthcare’s AI powerhouse with $275M Series F', 'author': 'Marina Temkin', 'category': 'Biotech & Health', 'start_index': 0}\n",
      "Content: Innovaccer aims to become healthcare’s AI powerhouse with $275M Series F\n",
      "When it comes to data, perhaps no sector has as much of it and in as many distinct silos as the healthcare industry.\n",
      "Hundreds of millions of patient records reside within various electronic health records (EHRs) maintained by vendors like Epic, Cerner, and Athena. Insurance companies hold extensive datasets on coverage, reimbursement rates, and patient demographics. Pharmacies and laboratories contribute further data points on medication usage and diagnostic results.\n",
      "Over the last decade or so, multiple companies have tried to unify all that patient data across health systems and care settings, but according to various investors, over the last few years, San Francisco-based Innovaccer has emerged as a leading player in this space.\n",
      "\n",
      "Source: {'url': 'https://techcrunch.com/2025/01/09/innovaccer-aims-to-become-healthcares-ai-powerhouse-with-275m-series-f/', 'date': '2025-01-09', 'title': 'Innovaccer aims to become healthcare’s AI powerhouse with $275M Series F', 'author': 'Marina Temkin', 'category': 'Biotech & Health', 'start_index': 814}\n",
      "Content: Innovaccer currently counts six of the U.S.’s top 10 healthcare systems as customers and is making strides in selling its platform to insurers, pharmaceuticals, and government organizations.\n",
      "The company already provides a suite of applications for value-based care, population health management, and customer relationship management (CRM), all built upon its cloud-based infrastructure.\n",
      "And now, Innovaccer plans to introduce multiple AI co-pilots and agents, including an AI medical scribe, a tool that simplifies prior authorizations, and another to help with denied claims.\n",
      "To support its grand ambition of becoming what Innovaccer co-founder and CEO Abhinav Shashank calls “a one-stop shop for healthcare AI solutions,” the company has raised a $275 million Series F from investors including B Capital Group, Banner Health, Danaher Ventures, Generation IM, Kaiser Permanente, and M12.\n",
      "\n",
      "Source: {'url': 'https://techcrunch.com/2025/01/09/innovaccer-aims-to-become-healthcares-ai-powerhouse-with-275m-series-f/', 'date': '2025-01-09', 'title': 'Innovaccer aims to become healthcare’s AI powerhouse with $275M Series F', 'author': 'Marina Temkin', 'category': 'Biotech & Health', 'start_index': 2504}\n",
      "Content: The fundraise confirms TechCrunch’s report from last May about Innovaccer being in talks to raise $250 million with Kaiser Permanente as a lead investor.\n",
      "Healthcare’s data fabric\n",
      "Innovaccer was founded in 2014 with the aim of unifying data for all types of enterprises. However, after three years, the company decided to start focusing exclusively on healthcare.\n",
      "“Healthcare lived in a pre-internet era. There was no connected fabric of information that existed,” Shashank told TechCrunch.\n",
      "So Innovaccer set out to build data infrastructure by connecting its platform to every major EHR system. The company spent about two years and more than $100 million building that connectivity, Shashank said.\n",
      "That effort seems to have paid off. Innovaccer’s revenue has increased by 50% every year for the past five years, and the company is on track to hit $250 million in annual recurring revenue (ARR) this year.\n",
      "\n",
      "Source: {'url': 'https://techcrunch.com/2025/01/09/innovaccer-aims-to-become-healthcares-ai-powerhouse-with-275m-series-f/', 'date': '2025-01-09', 'title': 'Innovaccer aims to become healthcare’s AI powerhouse with $275M Series F', 'author': 'Marina Temkin', 'category': 'Biotech & Health', 'start_index': 4164}\n",
      "Content: This vision has resonated with investors. Rashmi Gopinath, who first invested in Innovaccer when she was a managing director at M12 and is now a co-founder and managing partner at BAM Corner Point (also an investor), praised the company for being proactive at integrating AI solutions.\n",
      "“I think the rapid advancements that we’re seeing in generative AI is going to be a huge tailwind and momentum driver for the company,” she said.\n",
      "Innovaccer plans to develop some AI solutions in-house while partnering with or acquiring other promising AI products.\n",
      "Shashank said that if the company executes its vision well, Innovaccer will have an opportunity to become the biggest healthcare business within five years. “Fingers crossed,” he added.\n",
      "\n",
      "Source: {'url': 'https://techcrunch.com/2025/01/09/innovaccer-aims-to-become-healthcares-ai-powerhouse-with-275m-series-f/', 'date': '2025-01-09', 'title': 'Innovaccer aims to become healthcare’s AI powerhouse with $275M Series F', 'author': 'Marina Temkin', 'category': 'Biotech & Health', 'start_index': 1703}\n",
      "Content: This round has both primary and secondary components: Approximately 35% of the funds are allocated to provide some liquidity for the company’s seed and Series A investors, according to Shashank. Despite this secondary component, this is still enough capital to fuel Innovaccer’s next phase of growth.\n",
      "While the company declined to disclose its latest valuation, a source familiar with the deal said that the post-money valuation of the primary funding is approximately $3.45 billion. That’s a slight uptick from the $3.2 billion valuation Innovaccer earned when it raised its previous round of $150 million in late 2021, when pandemic tailwinds were still favorable. The secondary transaction likely valued the company at a significant discount to the primary, but that valuation couldn’t be learned.\n",
      "The fundraise confirms TechCrunch’s report from last May about Innovaccer being in talks to raise $250 million with Kaiser Permanente as a lead investor.\n",
      "Healthcare’s data fabric\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Innovaccer currently counts six of the U.S.’s top 10 healthcare systems as customers. However, the context does not specify its overall ranking among all healthcare companies in the U.S. Therefore, I still don't know its exact rank.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"I know for sure it it in U.S.'s top 10 healthcare systems in terms of customers. Please try again\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for step in url_graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}], \"url\": \"https://techcrunch.com/2025/01/09/innovaccer-aims-to-become-healthcares-ai-powerhouse-with-275m-series-f/\"},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOT RELATED TO APIS: modifying metadata: from time, to just date and removed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_postgres.vectorstores._get_embedding_collection_store.<locals>.EmbeddingStore object at 0x718a3c111f00>\n",
      "1261\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "from sqlalchemy.orm import Session\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "vectorstore = PGVector(\n",
    "    embeddings=embeddings, collection_name=\"my_docs2\",\n",
    "    connection=\"postgresql+psycopg://stefan:gigelfrone112@localhost:5432/techvector\", use_jsonb=True)\n",
    "\n",
    "with Session(vectorstore.session_maker.bind) as session:\n",
    "    docs = session.query(vectorstore.EmbeddingStore).all()\n",
    "\n",
    "print(docs[0])\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://techcrunch.com/2025/01/01/2024-the-year-silicon-valley-stifled-the-ai-doom-movement/', 'date': '2025-01-01', 'title': 'Silicon Valley stifled the AI doom movement in 2024', 'author': 'Maxwell Zeff', 'category': 'AI', 'start_index': 11322}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].cmetadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modifying metadata for time to just date\n",
    "\n",
    "from multiprocessing import connection\n",
    "\n",
    "date_conversion = {'January': '1', 'February': '2', 'March': '3', 'April': '4', 'May': '5', 'June': '6', 'July': '7', 'August': '8', 'September': '9', 'October': '10', 'November': '11', 'December': '12'}\n",
    "\n",
    "\n",
    "original_metadata = [doc.cmetadata for doc in docs]\n",
    "for doc in original_metadata:\n",
    "    # time = doc['time']\n",
    "    # time = time.replace(',', '')\n",
    "    # time = time.split(' ')\n",
    "    # time = f\"{time[2]}-{date_conversion[time[0]].zfill(2)}-{time[1].zfill(2)}\"\n",
    "    # doc['time'] = time\n",
    "    doc['date'] = doc['time']['date'] #{'date': doc['time']['date'], 'type': 'date'}\n",
    "    doc.pop('time')\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "texts = [doc.document for doc in docs]\n",
    "embeddings = [doc.embedding for doc in docs]\n",
    "text_embedding = list(zip(texts, embeddings))\n",
    "vector_store = PGVector.from_embeddings(text_embeddings=text_embedding, \n",
    "                                        embedding=embeddings,\n",
    "                                        metadatas=original_metadata,\n",
    "                                        connection=\"postgresql+psycopg://stefan:gigelfrone112@localhost:5432/techvector\",\n",
    "                                        collection_name=\"my_docs2\",\n",
    "                                        pre_delete_collection=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1261\n"
     ]
    }
   ],
   "source": [
    "ids_to_delete = [doc.id for doc in docs if \"image\" in doc.cmetadata]\n",
    "print(len(ids_to_delete))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.delete(ids_to_delete)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
